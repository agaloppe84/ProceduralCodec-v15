[![CI](https://github.com/agaloppe84/ProceduralCodec-v15/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/agaloppe84/ProceduralCodec-v15/actions/workflows/ci.yml)

# ProceduralCodec v15 â€” Codec procÃ©dural par tuiles (PC15)

**PC15** est un codec dâ€™image **entiÃ¨rement procÃ©dural** : lâ€™image est un **programme** (suite de gÃ©nÃ©rateurs + paramÃ¨tres quantifiÃ©s + seeds).
Lâ€™encodage sÃ©lectionne, **tuile par tuile** (GPU), le meilleur couple *(gÃ©nÃ©rateur, paramÃ¨tres, seed)* via un score **RD** (distorsion + coÃ»t en bits) et produit un bitstream **dÃ©terministe et idempotent**.

> âœ… **Ã‰tat v15.0.4** : encode/dÃ©code **Y**, bitstream **v15** (rANS auto-portant), tiling/blend, mÃ©triques, orchestration.
> ðŸ§  **PrÃ©-intÃ©gration IA (v15.1+)** : hooks *optionnels* cÃ´tÃ© encodeur (sÃ©lecteur de gÃ©nÃ©rateurs / init params / surrogate RD) â€” **sans changer le format**.
> ðŸ” **Monopackage** : `pc15` rÃ©-exporte les fonctions clÃ©s (`encode_y`, `decode_y`, `CodecConfig`, `rans_*`, `read/write_bitstream`, etc.).

---

[**ðŸ“š Documentation en ligne**](https://agaloppe84.github.io/ProceduralCodec-v15/)

## Sommaire

- [Installation rapide (utilisateur)](#installation-rapide-utilisateur)
- [Installation (dev)](#installation-dev)
- [Philosophie & architecture](#philosophie--architecture)
- [Mini-guide dâ€™utilisation](#mini-guide-dutilisation)
- [StratÃ©gie IA (v15.1+)](#stratÃ©gie-ia-v151)
- [Workflows recommandÃ©s](#workflows-recommandÃ©s)
- [Releases & CI](#releases--ci)
- [Contribuer](#contribuer)
- [Licence](#licence)
- [Delta checklist (Ã  garder alignÃ©)](#delta-checklist-Ã -garder-alignÃ©)

---

## Installation rapide (utilisateur)

> **PrÃ©-requis** : Python â‰¥ 3.10.
> Sur Colab/CPU, pas besoin de CUDA pour dÃ©coder/tests (le rendu procÃ©dural GPU est recommandÃ© mais optionnel pour la dÃ©mo).

```bash
pip install "git+https://github.com/agaloppe84/ProceduralCodec-v15@v15.0.4"
````

Utilisation â€œone-namespaceâ€ :

```python
import pc15 as pc
from pc15 import CodecConfig  # exportÃ© au top-level

cfg = CodecConfig(tile=256, overlap=24, lambda_rd=0.015, alpha_mix=0.7, seed=1234)
enc = pc.encode_y(img_y, cfg)             # -> {"bitstream": bytes, "bpp": float, "stats": dict, ...}
img_hat = pc.decode_y(enc["bitstream"])
```

> Astuce : `pc15.build_rans_tables`, `pc15.rans_encode`, `pc15.read_bitstream`, â€¦ sont aussi rÃ©-exportÃ©s.

---

## Installation (dev)

```bash
python -m venv .venv && source .venv/bin/activate
pip install -r configs/requirements.dev.txt

# Dev monorepo (editable) si vous travaillez sur les sous-modules
pip install -e packages/pc15core -e packages/pc15proc -e packages/pc15codec \
            -e packages/pc15vq   -e packages/pc15metrics -e packages/pc15data \
            -e packages/pc15viz  -e packages/pc15wf

# Sans GPU local ?
export PC15_ALLOW_CPU_TESTS=1
pytest -q
```

**CUDA** : recommandÃ© pour lâ€™encodage ; PyTorch 2.x.

---

## Philosophie & architecture

### Encode (Y puis CbCr 4:2:0)

1. **Tiling** : dÃ©coupe `(H,W)` en tuiles `TÃ—T` avec overlap `O`.
2. **Candidats** : batch GPU de rendus procÃ©duraux (gÃ©nÃ©rateur + params + seed).
3. **Score RD** : `D = Î±Â·(1-SSIM) + (1-Î±)Â·MSE_norm` + `Î»Â·bits` (estimÃ©s â†’ mesurÃ©s).
4. **SÃ©lection / beam** : top-1 (ou beam K=2â€“4), Ã©criture du **record tuile**.
5. **Entropie** : rANS sur symboles (IDs gÃ©nÃ©, indices QV, offsets, seed, flags).
6. *(Optionnel)* rÃ©sidu parcimonieux si tuile â€œhors-classeâ€.
7. **Chroma 4:2:0** aprÃ¨s la luminance.

### Decode

1. Lire **header** `PC15` + tables/codebooks.
2. Pour chaque tuile : dÃ©coder `(gen_id, qv_id|indices, seed, flags)` puis **re-rendre**.
3. **Blend** des tuiles (fenÃªtre Hann/cosine) sur lâ€™overlap.

---

## Mini-guide dâ€™utilisation

### 1) ProcÃ©dural (`pc15proc`)

```python
import torch
from pc15proc import list_generators, render

print(list_generators()[:10])
img = render(
    name="STRIPES", H=256, W=256,
    params={"freq": 6.0, "angle_deg": 15.0, "phase": 0.25, "contrast": 0.9},
    batch=1, device=("cuda" if torch.cuda.is_available() else "cpu"), dtype=torch.float16,
)  # -> Tensor [1,1,256,256] in [-1,1]
```

### 2) Encode/DÃ©code Y

```python
from pc15 import encode_y, decode_y, CodecConfig
cfg = CodecConfig(tile=256, overlap=24, lambda_rd=0.015, alpha_mix=0.7, seed=1234)
enc = encode_y(img_y, cfg)
bitstream, bpp = enc["bitstream"], enc["bpp"]
img_hat = decode_y(bitstream)
```

### 3) MÃ©triques

```python
from pc15 import psnr, ssim
print(psnr(img_y, img_hat), ssim(img_y, img_hat))
```

### 4) Bitstream helpers

```python
from pc15 import read_bitstream, write_bitstream, rans_encode, rans_decode, build_rans_tables
```

---

## StratÃ©gie IA (v15.1+)

> **Objectif** : accÃ©lÃ©rer/amÃ©liorer la **recherche** tout en **gardant le format identique**.
> Lâ€™IA ne touche **pas** au dÃ©codeur (bitstream inchangÃ©). Elle agit **uniquement** cÃ´tÃ© encodeur.

### Slots IA optionnels (AiHooks)

1. **M1 â€” Tile Selector** : prÃ©dire top-K gÃ©nÃ©rateurs plausibles par tuile (softmax sur {gÃ©nÃ©s}).
   **But** : ne rendre que K candidats pertinents â†’ **Ã—(2â€“10)** de gain selon *K* et la scÃ¨ne.

2. **M2 â€” Param Init** : prÃ©dire `(qv_id, offsets)` initiaux par gÃ©nÃ©.
   **But** : centrer la grille locale â†’ **moins dâ€™itÃ©rations** (coarseâ†’fine plus court).

3. **M3 â€” RD Surrogate** : estimer `\^RD` (ou `\^D`/`\^bits`) pour ordonner/Ã©crÃ©mer avant le score exact.
   **But** : calculer â€œcherâ€ uniquement sur le **top-M** candidates.

**Pipeline** : image â†’ tuiles â†’ *features* â†’ M1/M2/M3 â†’ **search** (coarseâ†’fine/beam) â†’ rANS â†’ bitstream.
**Fallback** : si `AiHooks=None`, lâ€™encodeur fonctionne **comme aujourdâ€™hui** (grilles par dÃ©faut).

### API (concept â€” v15.1)

```python
from pc15 import CodecConfig, encode_y
# from pc15core.ai import AiHooks, Selector, ParamPredictor, RdPredictor  # stubs v15.1 (Ã  venir)

hooks = None  # si non fourni => chemin actuel
# hooks = AiHooks(
#     selector=Selector(weights="m1_selector_v0.pt"),
#     param_predictor=ParamPredictor(weights="m2_params_v0.pt"),
#     rd_predictor=RdPredictor(weights="m3_rd_v0.pt"),
# )

cfg = CodecConfig(tile=256, overlap=24, lambda_rd=0.015, alpha_mix=0.7, seed=1234, ai=hooks)
enc = encode_y(img_y, cfg)
```

### RÃ´le des modÃ¨les

**M1 â€” Selector (top-K gÃ©nÃ©s)**

* *EntrÃ©e* : features de tuile (intensitÃ© normalisÃ©e, gradients, histos, pyramide multiscale).
* *Sortie* : `p(gen)` sur la banque de gÃ©nÃ©rateurs.
* *Perte* : CrossEntropy.
* *Usage* : on ne rend que les `K` meilleurs âžœ gros speed-up.

**M2 â€” ParamPredictor (init QV+offsets)**

* *EntrÃ©e* : patch + `gen_id`.
* *Sortie* : `(qv_id, offsets)` (offsets petits rÃ©els par dimension).
* *Pertes* : CE pour `qv_id`, L1/Huber pour offsets.
* *Usage* : centre la grille locale âžœ moins dâ€™itÃ©rations.

**M3 â€” RdPredictor (surrogate RD)**

* *EntrÃ©e* : features + `(gen, params_init)`
* *Sortie* : `\^RD` (ou `\^D` et `\^bits`)
* *Perte* : L1/HMSE ; calibration isotone possible.
* *Usage* : tri/Ã©crÃ©mage âžœ on calcule â€œexactâ€ seulement sur le top-M.

### DonnÃ©es & prÃ©paration (hors-ligne)

1. **Extraction tuiles**

   ```bash
   python tools/pc15learn/make_tiles_jsonl.py \
     --images /path/to/photos_v13 \
     --out datasets/tiles.jsonl \
     --tile 256 --overlap 24
   ```
2. **Features** : (HOG/grad, histos, pyramide), normalisation **gelÃ©e** (stats du train).
3. **Labels** : oracle (recherche exhaustive sur sous-set) ou heuristique â€œteacherâ€ v15.0.
4. **Split** : train/val/test **par image** (pas par tuile).
5. **Export** : `*.pt` + YAML de mÃ©ta (versions, normalisation, seed).

### DÃ©ploiement

* Charger les poids en CPU/GPU.
* Renseigner `CodecConfig(ai=hooks)` ; Ã©crire `header.meta.ai = {name, version, norm, sha256}`.
* ImplÃ©menter un **graceful fallback** (si poids manquants â†’ ignorer le hook, warning).

### Bench & objectifs

* **Temps** : viser Ã—3 sur lâ€™encodage Y avec M1 seul ; Ã—5â€“Ã—8 avec M1+M2 ; M3 selon budget.
* **QualitÃ©** : Î”PSNR / Î”SSIM â‰¤ 0.1â€“0.2 dB / 0.001 vs recherche brute (budget Ã©gal).
* **Bitrate** : Î”bpp â‰¤ 1â€“2 % sur corpus v13.

### Roadmap IA

* **v15.1** : stubs `AiHooks` + interfaces, heuristiques par dÃ©faut, extraction de tuiles.
* **v15.2** : M1 entraÃ®nÃ© (banque de gÃ©nÃ©s v15), ablation sur *K*.
* **v15.3** : M2 offsets + M3 surrogate RD ; benchmarks tempsÃ—qualitÃ© ; publication poids baseline.

---

## Workflows recommandÃ©s

1. **bootstrap_online (CPU)** : venv + install, log versions â†’ `reports/env_online_15.txt`
2. **proc_core_smoke (GPU)** : `pc15proc.render` 2â€“3 gÃ©nÃ©s, previews `outputs/`
3. **encode_batch (GPU)** : `.pc15` idempotents + stats/CSV
4. **metrics_rd (CPU/GPU)** : PSNR/SSIM + RD plots
5. **publish_models (CPU)** : tables rANS, codebooks QV, configs figÃ©es dans *Models*

---

## Releases & CI

* **Release** :

  ```bash
  git tag v15.0.4
  git push origin v15.0.4
  ```

  âžœ dÃ©clenche le job **release** si le workflow cible `on.push.tags`.

* **Ã‰viter les doubles builds** :
  Dans `ci.yml`, choisis **soit** `on.push.branches`, **soit** `on.push.tags` (pas les deux dans le mÃªme workflow).
  Alternative : sÃ©parer `ci.yml` (branches/PR) et `release.yml` (tags uniquement).

---

## Contribuer

* **Tests** : `pytest -q` (fallback CPU via `PC15_ALLOW_CPU_TESTS=1`).
* **Style** : black + ruff ; type hints.
* **PR** : inclure un test couvrant la surface API **et** le dÃ©terminisme (bitstream stable).

---

## Licence

Ã€ dÃ©finir (`LICENSE`).

---

## Delta checklist (Ã  garder alignÃ©)

* **Packaging**

  * `pyproject.toml` : pin NumPy compatible envs (ex. Colab Py3.12 : `numpy>=1.26,<2.0` OK) â€” ou matrice conditionnelle.
  * `pc15/__init__.py` : rÃ©-export **`CodecConfig`** + helpers (`encode_y`, `decode_y`, `rans_*`, `read/write_bitstream`, `score_rd_numpy`).
  * `__version__` = `15.0.4` cohÃ©rent avec le tag et les logs.

* **CI**

  * Un workflow pour branches/PR, un pour tags (optionnel) ; Ã©viter dÃ©clenchements doublons.
  * Artefacts utiles : `pytest-report.xml`, audits gÃ©nÃ©s, RD plots.

* **Docs**

  * Ce README couvre lâ€™IA et lâ€™API actuelle (single-package).
  * (Facultatif) Lien vers un notebook Colab dÃ©monstration.

* **Outils IA (Ã  venir)**

  * `tools/pc15learn/make_tiles_jsonl.py` (extraction tuiles/labels).
  * `pc15core/ai.py` : classes `AiHooks`, `Selector`, `ParamPredictor`, `RdPredictor` (stubs no-op si poids absents).


Parfait â€” voilÃ  **les 2 blocs prÃªts Ã  coller** dans ton README.

---

# Bloc README â€” Colab Quickstart (API + Drive + Hooks)

```python
#@title PC15 â€” Colab Quickstart (API + Drive + Hooks)
REPO = "agaloppe84/ProceduralCodec-v15"  # branche/tag via TAG
TAG  = "main"                            # ex: "v15.0.4" pour une release

import sys, subprocess, os, pathlib, time, json, math
PY = sys.executable
def sh(*args): print("âžœ", " ".join(map(str,args))); subprocess.run(list(args), check=True)

# 1) DÃ©pendances minimales (+ numpy pin Colab)
sh(PY, "-m", "pip", "install", "-q",
   "numpy>=1.26,<2.0", "Pillow>=10.0", "tqdm>=4.66", "matplotlib>=3.7")

# 2) Installer PC15 (monopackage avec sous-modules intÃ©grÃ©s)
sh(PY, "-m", "pip", "install", "-q", f"git+https://github.com/{REPO}@{TAG}")

# 3) Monter Google Drive (on nâ€™utilise QUE Drive ici)
from google.colab import drive
drive.mount("/content/drive", force_remount=True)

# 4) Config des chemins (tout passe par PathsConfig)
import pc15 as pc
print("pc15 version:", getattr(pc, "__version__", "unknown"))

DATASET_IMAGES = "/content/drive/MyDrive/procedural_datasets/pc_synth_v1_plus/images"  # <-- ton dataset (2000 photos)
BASE_DIR       = "/content/drive/MyDrive/pc15"                                         # rÃ©pertoire racine PC15 (artifacts, cacheâ€¦)

paths = pc.PathsConfig(
    base=BASE_DIR,
    dataset_images=DATASET_IMAGES,     # images d'entraÃ®nement/Ã©tiquetage
    artifacts_subdir="artifacts",      # ex: /content/drive/MyDrive/pc15/artifacts
    cache_subdir=".cache",             # ex: /content/drive/MyDrive/pc15/.cache
    labels_dir=None,                   # (optionnel) ex: "/content/drive/MyDrive/pc15/labels"
)
print("ENV:", pc.env_summary())

# 5) Smoke encode/decode (Y) + comparaison Hooks heuristiques vs baseline
import numpy as np
def _to_tensor(a):
    import torch
    return torch.as_tensor(a, dtype=torch.float32).unsqueeze(0).unsqueeze(0)

H=W=256
grad = np.linspace(0,1,W, dtype=np.float32)[None,:].repeat(H,axis=0)*0.8+0.1
yy   = _to_tensor(grad)

cfg = pc.CodecConfig(tile=256, overlap=24, lambda_rd=0.015, alpha_mix=0.7, seed=1234)

t0=time.perf_counter(); enc0 = pc.encode_y(yy, cfg); t_enc0=(time.perf_counter()-t0)*1000
t1=time.perf_counter(); recon= pc.decode_y(enc0["bitstream"], device="cpu"); t_dec=(time.perf_counter()-t1)*1000

# Hooks non-rÃ©seau de neurones (ex: top-K heuristique)
hooks = pc.HeuristicHooks(topk=8)
t2=time.perf_counter(); enc1 = pc.encode_y_with_hooks(yy, cfg, hooks=hooks); t_enc1=(time.perf_counter()-t2)*1000

# PSNR/SSIM (fallback NumPy si pc15.metrics indispo)
def _as_np(x):
    import torch
    return x.detach().cpu().float().squeeze().numpy() if isinstance(x, torch.Tensor) else np.asarray(x, np.float32)

try:
    PSNR = float(pc.psnr(yy, recon).item()); SSIM=float(pc.ssim(yy, recon).item())
except Exception:
    a=_as_np(yy); b=_as_np(recon)
    mse=float(np.mean((a-b)**2)); PSNR=20*math.log10(1.0)-10*math.log10(max(mse,1e-8))
    SSIM=max(0.0, 1.0-mse/(float(np.mean(a**2))+1e-8))

print(f"Baseline encode: {t_enc0:.1f} ms  | bytes={len(enc0['bitstream'])}")
print(f"Hooks encode   : {t_enc1:.1f} ms  | bytes={len(enc1['bitstream'])}")
print(f"Decode         : {t_dec:.1f} ms   | PSNR={PSNR:.2f} dB  SSIM={SSIM:.4f}")

# 6) Ã‰criture dâ€™artefacts sur Drive
LOG_DIR = pathlib.Path(paths.base)/"artifacts"; LOG_DIR.mkdir(parents=True, exist_ok=True)
HTML = LOG_DIR/"pc15_report.html"
HTML.write_text(
    f"<html><body><h1>PC15 Colab</h1>"
    f"<p>pc15={getattr(pc,'__version__','?')}</p>"
    f"<p>Baseline bytes={len(enc0['bitstream'])} | Hooks bytes={len(enc1['bitstream'])}</p>"
    f"<p>Encode0={t_enc0:.1f} ms | Encode1={t_enc1:.1f} ms | Decode={t_dec:.1f} ms</p>"
    f"<p>PSNR={PSNR:.2f} dB | SSIM={SSIM:.4f}</p></body></html>", encoding="utf-8"
)
print("Saved:", HTML)
```

---

# Bloc README â€” Arborescence standard pour tout **nouvel outil** intÃ©grÃ©

> RÃ¨gle dâ€™or : **jamais de code dâ€™outil Ã  la racine**.
> Chaque outil vit dans **`packages/pc15<outil>/src/pc15<outil>/...`** et le *namespace agrÃ©gateur* `pc15` rÃ©-exporte ce quâ€™il faut.

```
# Racine du repo
.
â”œâ”€ pyproject.toml                 # unique (build setuptools) â€” liste les src des sous-packages
â”œâ”€ src/
â”‚  â””â”€ pc15/
â”‚     â”œâ”€ __init__.py              # agrÃ©gateur : importe/alias les sous-packages et rÃ©-exporte l'API
â”‚     â””â”€ ...                      # (facultatif) petites faÃ§ades communes
â”œâ”€ packages/
â”‚  â”œâ”€ pc15codec/                  # existant
â”‚  â”‚  â””â”€ src/pc15codec/...
â”‚  â”œâ”€ pc15proc/                   # existant
â”‚  â”‚  â””â”€ src/pc15proc/...
â”‚  â”œâ”€ pc15metrics/                # existant
â”‚  â”‚  â””â”€ src/pc15metrics/...
â”‚  â”œâ”€ pc15data/                   # existant
â”‚  â”‚  â””â”€ src/pc15data/...
â”‚  â”œâ”€ pc15viz/                    # existant
â”‚  â”‚  â””â”€ src/pc15viz/...
â”‚  â”œâ”€ pc15wf/                     # existant
â”‚  â”‚  â””â”€ src/pc15wf/...
â”‚  â”œâ”€ pc15vq/                     # existant
â”‚  â”‚  â””â”€ src/pc15vq/...
â”‚  â””â”€ pc15learn/                  # **exemple dâ€™outil intÃ©grÃ©** (ex-tools)
â”‚     â””â”€ src/
â”‚        â””â”€ pc15learn/
â”‚           â”œâ”€ __init__.py        # expose lâ€™API de lâ€™outil (ex: HeuristicHooks, PathsConfig, make_labels, â€¦)
â”‚           â”œâ”€ paths.py           # gestion des chemins paramÃ©triques (Colab/Drive/locaux)
â”‚           â”œâ”€ ai_hooks.py        # hooks heuristiques + encode_y_with_hooks(...)
â”‚           â””â”€ make_labels.py     # CLI/func dâ€™extraction de tuiles/labels (v15.1+)
â”œâ”€ tests/
â”‚  â”œâ”€ test_api_contracts.py
â”‚  â”œâ”€ test_pc15learn_hooks.py     # tests du nouvel outil (import via `from pc15.learn import ...`)
â”‚  â””â”€ test_pc15learn_labels.py
â””â”€ ...
```

**Checklist dâ€™intÃ©gration dâ€™un nouvel outil `pc15<outil>` :**

1. **Dossier** : `packages/pc15<outil>/src/pc15<outil>/...` (pas de code outil ailleurs).

2. **`pyproject.toml`** (racine) â†’ ajouter le chemin dans :

   ```toml
   [tool.setuptools.packages.find]
   where = [
     "src",
     "packages/pc15core/src", "packages/pc15proc/src", "packages/pc15codec/src",
     "packages/pc15vq/src", "packages/pc15metrics/src", "packages/pc15data/src",
     "packages/pc15viz/src", "packages/pc15wf/src",
     "packages/pc15learn/src"        # <-- ajouter votre nouvel outil ici
   ]
   ```

   *(Remplace `pc15learn` par `pc15<outil>` pour le prochain outil.)*

3. **AgrÃ©gateur `src/pc15/__init__.py`** â†’ alias propre :

   ```python
   # Exemple pour un outil 'pc15learn'
   try:
       import pc15learn as learn
       from pc15learn import HeuristicHooks, PathsConfig, encode_y_with_hooks, env_summary, make_labels
   except Exception:
       learn = None
       HeuristicHooks = PathsConfig = encode_y_with_hooks = env_summary = make_labels = None  # type: ignore

   __all__ += [
       "learn", "HeuristicHooks", "PathsConfig", "encode_y_with_hooks", "env_summary", "make_labels"
   ]
   ```

   *MÃªme pattern pour tout `pc15<outil>` futur (ex: `pc15train`, `pc15serve`, â€¦).*

4. **Tests** : placer les tests Ã  la racine `tests/` et importer via **`from pc15.<alias> import ...`**
   (on ne rÃ©fÃ©rence jamais `packages/...` directement dans les tests).

5. **Docs** : documenter lâ€™API dans le README principal (sections *Quickstart/Colab* et *Arborescence*).

Câ€™est tout â€” avec Ã§a, **un seul `pip install pc15`** expose lâ€™outil **et** lâ€™agrÃ©gateur `pc15` rÃ©-exporte lâ€™API utile.


## Step 0 â€” PrÃ©-flight & gels (v15)

- **CodecConfig** unique (tile/overlap/Î»/Î±/rans_id) â€” `from pc15codec.config import CodecConfig`.
- **Tables rANS gelÃ©es** packagÃ©es sous `pc15codec.data.rans` + override via `PC15_MODELS_DIR/rans/<id>.json`. <!-- [ML] -->
- **Header v15 + CRC32** (`pack_v15`/`unpack_v15`) â€” framing stable.
- **Seed policy** dÃ©terministe (`pc15codec.seed.tile_seed`) â€” idempotence stricte.
- **Bitstreams I/O** atomique (`read_bitstream` / `write_bitstream`). <!-- [STORE:OVERWRITE] -->
- **Chemins paramÃ©triques** (`PathsConfig`) + `outputs_path`/`artifacts_path`. <!-- [STORE:OVERWRITE]/[STORE:CUMULATIVE] -->
- **Tests** OK : public_api, header_crc, seed_policy, rans_tables (+ *futureproof* skips).

Parfait â€” voilÃ  le **bloc README Step 1** mis Ã  jour, incluant les derniers correctifs (indices sans overshoot + crop au bord), les fenÃªtres **Hann/Tukey/Kaiser**, et le **seam penalty**. Tu peux **copier/coller** tel quel dans ton `README.md`.

---

## Step 1 â€” Tiling & Blend + Tile Records (v15)

### TL;DR

* **Tiling** paramÃ©trique (grille robuste, **sans overshoot**).
* **Blend** par *partition of unity* (normalisation par somme des poids) avec fenÃªtres **Hann** *(dÃ©faut)*, **Tukey** *(recommandÃ©e)*, **Kaiser**.
* **Crop automatique** au bord pour les tuiles partielles (pas dâ€™erreur de taille).
* **Seam penalty mask** pour pÃ©naliser lÃ©gÃ¨rement les coutures dans le score RD.
* **TileRec** (format dâ€™enregistrement de tuile, sans rANS pour lâ€™instant).

---

### API (import)

```python
from pc15codec.tiling import TileGridCfg, tile_image, blend, seam_penalty_mask
from pc15codec.bitstream import TileRec
```

---

### Tiling (grille)

```python
grid = TileGridCfg(size=256, overlap=24)    # vÃ©rifs intÃ©grÃ©es : size>0 et 0<=overlap<size
spec = tile_image(y, grid)                  # y: Tensor[1,1,H,W]
# spec: TileBatchSpec(H, W, size, overlap, ny, nx, starts) + .count
```

**Invariants & garanties**

* Les positions de dÃ©part sont **monotones** et **ne dÃ©passent jamais** `L - size`.
* La derniÃ¨re tuile est **forcÃ©e** Ã  `L - size` pour couvrir le bord.
* `spec.starts` est de longueur `spec.count = spec.ny * spec.nx`.

---

### Blend (partition of unity)

```python
y_hat = blend(
    tiles, spec, H, W,                 # tiles: Tensor[N,1,size,size], N == spec.count
    window="hann",                     # "hann" (dÃ©faut) | "tukey" | "kaiser"
    window_params=None                 # {'alpha':...} pour tukey, {'beta':...} pour kaiser
)
```

**Comportement**

* Accumulation pondÃ©rÃ©e `sum(tiles * w)` puis **normalisation** par `sum(w)` pixel-par-pixel.
* **Crop automatique** de la fenÃªtre et de la tuile quand une tuile touche le bord (aucune exception sur les tailles).
* FenÃªtres 2D **sÃ©parables** (wyâŠ—wx) pour robustesse et perf.

**FenÃªtres**

* **Hann** *(dÃ©faut)* : simple, fiable.
* **Tukey** *(recommandÃ©e prod)* : plateau central + bords lissÃ©s.

  * `alpha` **auto** â‰ˆ `2 * overlap / size` (bornÃ© Ã  [0,1]).
  * Exemple : `blend(..., window="tukey")` ou `blend(..., window="tukey", window_params={"alpha":0.5})`.
* **Kaiser** : bords plus â€œraidesâ€ (textures trÃ¨s structurÃ©es).

  * `beta` typique `6.5â€“8.0`.
  * Exemple : `blend(..., window="kaiser", window_params={"beta":6.5})`.

---

### Seam penalty (RD)

```python
m = seam_penalty_mask(size=grid.size, overlap=grid.overlap, power=1.5)  # Tensor[size,size] âˆˆ [0,1]
# Exemple dâ€™intÃ©gration dans le score RD :
# D_base = Î±Â·(1-SSIM) + (1-Î±)Â·MSE_norm
# D = (1 + Î³Â·m) * D_base    # Î³ â‰ˆ 0.25â€¦0.5 selon la sensibilitÃ© aux coutures
```

* `mâ‰ˆ0` au centre, `â†’1` vers les bords ; `power>1` accentue la pÃ©nalitÃ© prÃ¨s des edges.
* **But** : Ã©viter que la recherche sÃ©lectionne des candidats â€œbons au centre mais mauvais sur les couturesâ€.

> ðŸ’¬ **Commentaire stockage/IA** : ce masque est **calculÃ© Ã  la volÃ©e** (pas de stockage). La pondÃ©ration RD ne stocke rien non plus. *(Aucun artefact IA/entrainement ici.)*

---

### Tile records (bitstream)

```python
rec = TileRec(tile_id=0, gen_id=7, qv_id=3, seed=42,
              rec_flags=0, payload_fmt=0, payload=b"")   # pas de rANS encore
d = rec.to_dict(); rec2 = TileRec.from_dict(d)           # round-trip dict
```

* **Objectif Step 1** : typer la structure de record par tuile.
* **Pas de sÃ©rialisation rANS** encore (payload permissif, Ã©ventuellement vide).
* **Stockage** : quand on activera rANS, ce sera un bloc **[STORE:OVERWRITE]** packÃ© dans le bitstream. Ici, rien nâ€™est Ã©crit.

---

### Exemples

**Hann (dÃ©faut)**

```python
H, W = 512, 512
y     = torch.zeros((1,1,H,W), device=dev, dtype=dtype)
grid  = TileGridCfg(size=128, overlap=16)
spec  = tile_image(y, grid)
tiles = torch.rand((spec.count, 1, grid.size, grid.size), device=dev, dtype=dtype)

y_hat = blend(tiles, spec, H, W)   # partition of unity, crop auto au bord
```

**Tukey (prod)**

```python
y_hat = blend(tiles, spec, H, W, window="tukey")  # alpha auto en fonction overlap/size
```

**Kaiser**

```python
y_hat = blend(tiles, spec, H, W, window="kaiser", window_params={"beta": 6.5})
```

---

### Edge cases & perfs

* **Bords** : pas de mismatch â€” crop appliquÃ© sur (tuile, fenÃªtre) au besoin.
* **CPU/GPU** : supportÃ©s ; `float16` en CUDA, `float32` en CPU.
* **Stride** = `size - overlap` (implÃ©mentÃ© via indices monotones).
* **Aucun I/O** ici (pas de disque), tout est in-mem.

---

### Tests (CI)

* âœ… `test_step1_tiling_blend_shapes.py` â€” formes, finitude, dynamique [0..1].
* âœ… `test_step1_tilerec_roundtrip.py` â€” round-trip dict `TileRec`.
* âœ… `test_api_contracts.py` â€” micro-pipeline STRIPES + tiling/blend.
* ðŸ”œ Tests rANS/payload restent **skipped** jusquâ€™au Step 2.

> Pour forcer les tests CPU : `PC15_ALLOW_CPU_TESTS=1` (dÃ©jÃ  dans le workflow).
> **PyTorch CPU 2.3.1** OK ; `kaiser_window` dispose dâ€™un fallback interne si absent.

---

### Roadmap (prochain bloc)

* **Step 2 â€” Bitstream records** : sÃ©rialisation multi-tuiles, payload rANS (tables gelÃ©es v15 + override), read/write des records avec CRC, invariants + tests round-trip.
* **Step 3 â€” Recherche RD** : boucle coarseâ†’fine + seam penalty intÃ©grÃ©e, beam K (optionnel), early-exit, mÃ©triques PSNR/SSIM mixÃ©es.

---
